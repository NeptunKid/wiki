
## Background:
h(x) = Z (P(x) log2P(x))  x (- X
tf * idf

## Steps:

1. Define:  Problem F(x) - > V
2. Model:   a. Probability based:   E1, E2, E3..  b. Vector based…  
3. Train: Supervised & Unsupervised  (with label)
4. Evaluation

## Formula
1. Bayes:  P(A|B) = P(A)P(B|A) / P(B)
 贝耶斯分类系统：  P(C|X1X2X3...)  = P(C)P(X1X2X3...|C)  / P(X1X2..Xn)  
  if 互不相关， ＝ P(C)P(X1|C)P(X2|C)...P(Xn|C) / P(X1X2..Xn)  - Naive Bayes
2. 线性模型： F = w1.x+w2.x+...wn.x
F(x1x2x3...x) = 0;
F(x1x2x3...x) = 1;
线性回归：设置learning rate: b = 0.1  
sgd： 
3. Sigmoid
<img src='http://d.hiphotos.baidu.com/baike/s%3D99/sign=a46bd6f1dd33c895a27e9472d01340df/0df3d7ca7bcb0a4659502a5f6f63f6246b60af62.jpg'></img>

